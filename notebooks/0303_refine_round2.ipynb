{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33933dbb-a304-4cab-a850-ed0925712541",
   "metadata": {},
   "source": [
    "# Refine Round 2\n",
    "\n",
    "Now we have two sets of annotations let's create new annotations using each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420c8379-9cd6-401c-9706-9f46fff8e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bookfinder\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e260a5-dcdb-4f75-9ca7-0c6d997853f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc15dc-426f-4dd2-ac41-48750e8b3aa3",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "## Read in existing annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b912dbb5-196d-4b7a-9929-93424b3a9756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hnbook_classify.jsonl', 'hnbook_binary_02.jsonl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_annotations = Path('data/00_annotations/03_book_binary/')\n",
    "\n",
    "[x.name for x in dir_annotations.glob('*.jsonl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bad9080-4c98-455d-830f-3615410b1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.concat([\n",
    "    pd.read_json(path, lines=True)\n",
    "    for path in dir_annotations.glob('*.jsonl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "985b95f2-1032-4cab-aed9-0778d1a41791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reject    153\n",
       "accept     29\n",
       "ignore      6\n",
       "Name: answer, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df_in.answer.value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d0d57-8b3d-4836-9891-23d9054d82dc",
   "metadata": {},
   "source": [
    "## Stratified Sample\n",
    "\n",
    "Create a 1:1 sample of reject and accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3c1533-e493-42b7-ab98-4e21de9b2a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample = counts.loc[['reject', 'accept']].min()\n",
    "\n",
    "n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb17a14e-a146-4fc0-be07-4aaf5ae7b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accept    29\n",
       "reject    29\n",
       "Name: answer, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = (\n",
    "    df_in\n",
    "    .query('answer != \"ignore\"')\n",
    "    .groupby('answer', group_keys=False)\n",
    "    .apply(lambda x: x.sample(min(len(x), n_sample)))\n",
    ")\n",
    "\n",
    "df_train.answer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31919d-3f3a-42dc-862c-48744aaa0057",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We'll use [SetFit](https://huggingface.co/blog/setfit) which is fast and good for few-shot text classification like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfcf04f6-97d6-48d8-9217-84e762b3dd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'meta', '_input_hash', '_task_hash', 'label', '_view_id', 'answer', '_timestamp', '__index_level_0__'],\n",
       "    num_rows: 58\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209e2ed-a409-4623-89ed-39cd8b50c001",
   "metadata": {},
   "source": [
    "Use `all-MiniLM-L6-v2` which is very fast, while still quite accurate (based on the SentenceTransformers [benchmarks](https://www.sbert.net/docs/pretrained_models.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c224e589-57a4-4ddf-b57f-06fae08c3432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SetFitModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77098070-ee7a-492a-8f01-a5715530e8a8",
   "metadata": {},
   "source": [
    "We'll leave all these as their default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae37002f-724c-444a-861f-6f0a011d15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=None,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    metric=\"accuracy\",\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # The number of text pairs to generate for contrastive learning\n",
    "    num_epochs=1, # The number of epochs to use for constrastive learning\n",
    "    column_mapping={\"text\": \"text\", \"answer\": \"label\"} # Map dataset columns to text/label expected by trainer\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c667ee0-87b2-4a41-be84-056566f01096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n",
      "***** Running training *****\n",
      "  Num examples = 2320\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 145\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d02dd68e2744c5bb4cc94e1f4c487e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68132c889cd4a738c4b0006ddbc971e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c94af2-0adf-40c3-807e-b2c769815eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('data/06_models/setfit_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0add5-f4d9-43dc-8d82-6507052fbfd2",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "Now let's perform inference with our trained model on our data to annotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e740b1a-5ba5-4014-83ea-67c0c4c13f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_parquet('data/02_intermediate/hn_enriched.parquet')\n",
    "    .query('bucket<3 & text_length > 0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "787d6836-cf98-4c65-8d63-c752c75bd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.clean_text.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36721e3-87cf-42a1-a7c1-5ad5a1463a90",
   "metadata": {},
   "source": [
    "Get the column corresponding to 'accept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b173f566-d61f-40c7-a5f1-92946116fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['accept', 'reject'], dtype='<U6')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_head.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdd72bd4-e2d3-4ce2-8fe1-921a1886bb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept_idx = list(model.model_head.classes_).index('accept')\n",
    "accept_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e6f81-3cca-4fe4-ba00-cbd002fd687c",
   "metadata": {},
   "source": [
    "Calculate the accept probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "672da089-0624-49d4-bf0c-1204c15e11e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 7.92 s, total: 2min 17s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "probs = model.predict_proba(text)[:,accept_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf590783-ca48-488a-b5b5-a07343c5e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prob'] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc0d63-dfba-45bb-9426-8ea41a7d1135",
   "metadata": {},
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1df8a06-a38d-44df-879d-585efd7c417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ad0d9a6-ff84-404f-8e0e-5c97ae3473c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26099778</th>\n",
       "      <td>Someone on HN mentioned the book 'Titanosaur: Discovering the World's Largest Dinosaur' written by the two paleontologists who led the discovery - José Luis Carballido and Diego Pol. It's illustrated and seems to have very good reviews.\\n\\nhttps://kids.scholastic.com/kids/book/titanosaur-by-jose-luis-carballido/\\n\\nPersonally, when I was a teen, the first 3 Jurassic Park films whirled my brain and had nice vivid dreams about the island and dinos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26753531</th>\n",
       "      <td>As someone whose great uncles worked in the steel factories nearby, whose parents before that labored in the cotton fields, I can also testify the multi-century efforts of Black workers who fought the “hands that was fedding them”. America's Johannesburg [1] and Hammer and Hoe [2] for reference.\\n\\n[1] https://ugapress.org/book/9780820356273/americas-johannesburg/\\n\\n[2] https://uncpress.org/book/9781469625485/hammer-and-hoe/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26756574</th>\n",
       "      <td>It seems this book's colours were hand-painted, but I might as well mention two famous mid-C19 examples of colour printing, when (IIRC; I am not an expert) high-quality colour printing was still very expensive and rare:\\n\\n* the \"Sobieski Stewarts'\" dodgy Vestiarium Scoticum: https://en.wikipedia.org/wiki/Vestiarium_Scoticum\\n\\n&gt; It was from Eilean  Aigas, in 1842, that the brothers at last published their famous manuscript, Vestiarium Scoticum . It appeared in a sumptuous edition limited to fifty copies. The series of coloured illustrations of tartans was the first ever to be published and was a triumph over technical difficulties. These illustrations were executed by a new process of ‘machine printing’ and, in the words of a scholar writing fifty years later, ‘for beauty of execution and exactness of detail  have not been  excelled by any  method of colour-printing subsequently invented’.\\n\\n&gt; Hugh Trevor-Roper, \"The Invention of Tradition: The Highland Tradition of Scotland\"\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26937872</th>\n",
       "      <td>If anyone wants to read about mystery/crime investigation in Ancient Rome, the SPQR series is a bunch of fun fictional books (of questionable historical accuracy):\\n\\n&gt; The stories are told in first-person form by Senator Decius Caecilius Metellus the Younger (born c 90-95 BC), nephew of Metellus Pius and member of the powerful Caecilius Metellus family of the Roman Senate. The stories are told in flashback-form by the old Decius, writing during the reign of Augustus Caesar. The stories range from 70 BC (The King's Gambit) to 20 BC (\"The King of Sacrifices\").\\n\\n* https://en.wikipedia.org/wiki/SPQR_series\\n\\nFor non-fiction, see Infamy: The Crimes of Ancient Rome by Jerry Toner:\\n\\n&gt; Join the historian Jerry Toner on a detective's hunt to discover the extent of Rome's crimes.\\nFrom the sexual peccadillos of Tiberius and Nero to the chances of getting burgled if you left your apartment unguarded (pretty high, especially if the walls were thin enough to knock through) he leaves no st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28060693</th>\n",
       "      <td>The one really first rate recent SF novel I can recall is: \"This is how you lose the time war\" [0] by Amal El-Mohtar and Max Gladstone. It's far from being Hard SF if you like that (I do) but the humour and poetry of it won me over very fast. I bought it purely on the basis of the delicious title!\\n\\nThe \"Lady Astronaut\" series [1] by Mary Robinette Kowal is not first rate, but it is reliably entertaining and a fairly Hard SF alternate history with some interesting choices.\\n\\nI'm going to take a liberty and also recommend a much older SF book that I rarely see mentioned; \"Fiasco\" by Stanisław Lem. This one's all about the characterization and the big picture of humanity's fatal flaws. Not hard SF as such, but he tells a good tall tale when he needs to mess with space and time.\\n\\n[0] https://en.wikipedia.org/wiki/This_Is_How_You_Lose_the_Time_War\\n\\n[1] https://www.goodreads.com/series/193730-lady-astronaut-universe\\n\\n[1] https://en.wikipedia.org/wiki/Fiasco_(novel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26698876</th>\n",
       "      <td>Not a biography, but a collection of memorial articles and reminisces:\\n\\nhttps://www.elsevier.com/books/landau-the-physicist-and-the-man/j-b-sykes/978-0-08-036383-7\\n\\nAlso, I found the autobiography by Sagdeev (one of the &lt;50 who finished the \"Theoretical Minimum\" of Landau) to have some nice anecdotes about Landau:\\n\\nRoald Sagdeev, \"The Making of a Soviet Scientist: My Adventures in Nuclear Fusion and Space\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25752028</th>\n",
       "      <td>If you're into Cal Newport, he's got a new book coming out that seems related:\\n\\nhttps://bookshop.org/books/a-world-without-email-reimagining-work-in-an-age-of-communication-overload/9780525536550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27229205</th>\n",
       "      <td>Speaking about his short stories, read \"The Overcoat\"/\"The Mantle\" by Gogol. Dostoevsky is said to have said that \"we all came out of 'the overcoat' of/by Gogol\", in the sense that the tradition of deep compassion with the simple/poor in Russian literature started with this work.\\nhttps://www.gutenberg.org/files/36238/36238-h/36238-h.htm#Page_19\\n\\nAnother very good (and short one) is 'the Nose'  - this one is quite surrealistic, it's a hundred years ahead of its time.\\nhttps://www.gutenberg.org/files/36238/36238-h/36238-h.htm#Page_67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29174998</th>\n",
       "      <td>Check out the interrogation scene in \"Ghost Fleet\" (2015).\\n\\nIt's excerpted here if you don't want to read the whole book:\\n\\nhttps://gizmodo.com/how-ghost-fleet-nails-the-perfect-vision-of-world-war-i-1713881852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28072509</th>\n",
       "      <td>I really enjoyed “XX” by Rian Hughes — a completely new kind of sci fi. Like my other fav sci-fi book Three Body Problem, it all starts with a signal from space, but then... very boldly imagined book and deserves much more praise than it seems to have gotten.\\n\\nAmazon.com: XX (9781419750694): Hughes, Rian: Books https://www.amazon.com/dp/1419750690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       clean_text\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "26099778                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Someone on HN mentioned the book 'Titanosaur: Discovering the World's Largest Dinosaur' written by the two paleontologists who led the discovery - José Luis Carballido and Diego Pol. It's illustrated and seems to have very good reviews.\\n\\nhttps://kids.scholastic.com/kids/book/titanosaur-by-jose-luis-carballido/\\n\\nPersonally, when I was a teen, the first 3 Jurassic Park films whirled my brain and had nice vivid dreams about the island and dinos.\n",
       "26753531                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            As someone whose great uncles worked in the steel factories nearby, whose parents before that labored in the cotton fields, I can also testify the multi-century efforts of Black workers who fought the “hands that was fedding them”. America's Johannesburg [1] and Hammer and Hoe [2] for reference.\\n\\n[1] https://ugapress.org/book/9780820356273/americas-johannesburg/\\n\\n[2] https://uncpress.org/book/9781469625485/hammer-and-hoe/\n",
       "26756574  It seems this book's colours were hand-painted, but I might as well mention two famous mid-C19 examples of colour printing, when (IIRC; I am not an expert) high-quality colour printing was still very expensive and rare:\\n\\n* the \"Sobieski Stewarts'\" dodgy Vestiarium Scoticum: https://en.wikipedia.org/wiki/Vestiarium_Scoticum\\n\\n> It was from Eilean  Aigas, in 1842, that the brothers at last published their famous manuscript, Vestiarium Scoticum . It appeared in a sumptuous edition limited to fifty copies. The series of coloured illustrations of tartans was the first ever to be published and was a triumph over technical difficulties. These illustrations were executed by a new process of ‘machine printing’ and, in the words of a scholar writing fifty years later, ‘for beauty of execution and exactness of detail  have not been  excelled by any  method of colour-printing subsequently invented’.\\n\\n> Hugh Trevor-Roper, \"The Invention of Tradition: The Highland Tradition of Scotland\"\\n\\n...\n",
       "26937872  If anyone wants to read about mystery/crime investigation in Ancient Rome, the SPQR series is a bunch of fun fictional books (of questionable historical accuracy):\\n\\n> The stories are told in first-person form by Senator Decius Caecilius Metellus the Younger (born c 90-95 BC), nephew of Metellus Pius and member of the powerful Caecilius Metellus family of the Roman Senate. The stories are told in flashback-form by the old Decius, writing during the reign of Augustus Caesar. The stories range from 70 BC (The King's Gambit) to 20 BC (\"The King of Sacrifices\").\\n\\n* https://en.wikipedia.org/wiki/SPQR_series\\n\\nFor non-fiction, see Infamy: The Crimes of Ancient Rome by Jerry Toner:\\n\\n> Join the historian Jerry Toner on a detective's hunt to discover the extent of Rome's crimes.\\nFrom the sexual peccadillos of Tiberius and Nero to the chances of getting burgled if you left your apartment unguarded (pretty high, especially if the walls were thin enough to knock through) he leaves no st...\n",
       "28060693                   The one really first rate recent SF novel I can recall is: \"This is how you lose the time war\" [0] by Amal El-Mohtar and Max Gladstone. It's far from being Hard SF if you like that (I do) but the humour and poetry of it won me over very fast. I bought it purely on the basis of the delicious title!\\n\\nThe \"Lady Astronaut\" series [1] by Mary Robinette Kowal is not first rate, but it is reliably entertaining and a fairly Hard SF alternate history with some interesting choices.\\n\\nI'm going to take a liberty and also recommend a much older SF book that I rarely see mentioned; \"Fiasco\" by Stanisław Lem. This one's all about the characterization and the big picture of humanity's fatal flaws. Not hard SF as such, but he tells a good tall tale when he needs to mess with space and time.\\n\\n[0] https://en.wikipedia.org/wiki/This_Is_How_You_Lose_the_Time_War\\n\\n[1] https://www.goodreads.com/series/193730-lady-astronaut-universe\\n\\n[1] https://en.wikipedia.org/wiki/Fiasco_(novel)\n",
       "26698876                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Not a biography, but a collection of memorial articles and reminisces:\\n\\nhttps://www.elsevier.com/books/landau-the-physicist-and-the-man/j-b-sykes/978-0-08-036383-7\\n\\nAlso, I found the autobiography by Sagdeev (one of the <50 who finished the \"Theoretical Minimum\" of Landau) to have some nice anecdotes about Landau:\\n\\nRoald Sagdeev, \"The Making of a Soviet Scientist: My Adventures in Nuclear Fusion and Space\"\n",
       "25752028                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    If you're into Cal Newport, he's got a new book coming out that seems related:\\n\\nhttps://bookshop.org/books/a-world-without-email-reimagining-work-in-an-age-of-communication-overload/9780525536550\n",
       "27229205                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Speaking about his short stories, read \"The Overcoat\"/\"The Mantle\" by Gogol. Dostoevsky is said to have said that \"we all came out of 'the overcoat' of/by Gogol\", in the sense that the tradition of deep compassion with the simple/poor in Russian literature started with this work.\\nhttps://www.gutenberg.org/files/36238/36238-h/36238-h.htm#Page_19\\n\\nAnother very good (and short one) is 'the Nose'  - this one is quite surrealistic, it's a hundred years ahead of its time.\\nhttps://www.gutenberg.org/files/36238/36238-h/36238-h.htm#Page_67\n",
       "29174998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Check out the interrogation scene in \"Ghost Fleet\" (2015).\\n\\nIt's excerpted here if you don't want to read the whole book:\\n\\nhttps://gizmodo.com/how-ghost-fleet-nails-the-perfect-vision-of-world-war-i-1713881852\n",
       "28072509                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I really enjoyed “XX” by Rian Hughes — a completely new kind of sci fi. Like my other fav sci-fi book Three Body Problem, it all starts with a signal from space, but then... very boldly imagined book and deserves much more praise than it seems to have gotten.\\n\\nAmazon.com: XX (9781419750694): Hughes, Rian: Books https://www.amazon.com/dp/1419750690"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('prob', ascending=False)[['clean_text']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755474fb-f1d9-4ae4-af71-ab7e48a8f6b0",
   "metadata": {},
   "source": [
    "# Stratified sample for annotation.\n",
    "\n",
    "We want to get some interesting examples to annotate.\n",
    "\n",
    "If we pick at random, most won't have titles of books or works of art.\n",
    "Instead sample equally from each decile to get a mixture of positives, negatives and borderline cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc9f03dc-08ac-4998-8ed2-5da237ab2ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['prob'].hist(bins=20, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4317b787-37d7-41e7-b860-dd59a290a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bucket'] = (df['prob']*10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b39df3-5932-4781-adb8-c3c1afca7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a82ce-0f63-49ce-ab5a-525644d084cc",
   "metadata": {},
   "source": [
    "Remove the items that are already annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57515f9c-5ef7-47ad-abf0-cf77ace2e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_ids = [x['id'] for x in df_in['meta'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1287972f-2123-4b90-855f-2e3e905a570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = (\n",
    "    df.loc[~df.index.isin(annotated_ids)]\n",
    "    .groupby('bucket', group_keys=False)\n",
    "    .apply(lambda x: x.sample(min(len(x), n_sample)))\n",
    "    .sample(frac=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be89ec90-db57-4af9-bcc8-709ca79e4684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ec834b1-e128-47a8-92c3-a57ccde3467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    20\n",
       "0    20\n",
       "1    20\n",
       "7    20\n",
       "4    20\n",
       "8    20\n",
       "3    20\n",
       "6    20\n",
       "9    20\n",
       "5    20\n",
       "Name: bucket, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.bucket.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4375eaed-357d-4792-bccd-b9d025d4d5b7",
   "metadata": {},
   "source": [
    "Save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10a69011-8e0d-46b1-9c00-7c2325cba4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/02_intermediate/hn_sample_2.jsonl', 'w') as f:\n",
    "    for id, row in df_out.iterrows():\n",
    "        data = {\"text\": row[\"clean_text\"], \"meta\": {\"id\": id}}\n",
    "        print(json.dumps(data), file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
